练习题：

1.r2_score的计算公式如下：（本质上是以均值模型作为baseline model，计算该模型相较于它的好坏）
$$
R^2(y,\hat{y})=1-\frac{\sum_{i=0}^{n-1}(y_i-\hat{y_i})^2}{\sum_{i=0}^{n-1}(y_i-\overline{y})^2}
$$
​	mse计算公式如下:
$$
MSE(y,\hat{y})=\frac{1}{n}\sum_{i=0}^{n-1}(y_i-\hat{y}_i)^2
$$
​	二者的区别是$R^2(y,\hat{y})=1-\frac{MSE(y,\hat{y})}{\sigma^2}$​，其中$\sigma$表示y的标准差​​​。

MSE是带量纲的，而且结果为量纲的平方，而r2_score是不带量纲的，可以比较模型在不同量纲数据上的好坏。





2.不会。闵式距离为：
$$
D（x,y）=(\sum_{u=1}^n|x_u-y_u|^p)^{\frac{1}{p}}
$$
嵌入向量是依据决策森林样本叶节点落位而进行multi_hot encoding的一个结果（对应位取值为1，其他为0），只要叶子节点编号的每个维度的权重一样（这里都是1），改变叶子节点编号顺序就对距离的度量不会产生影响（进的还是近，远的还是远）。



知识回顾

1.在随机森林对样本进行bootstrap采样时，由于bootstrap采样的特点，会导致大约有$e^{-1}=0.368$​的数据没有被选出来参与训练，我们称之为袋外数据(即oob -data),每一个基学习器训练完后，我们都对oob数据进行预测，每个样本对应的oob_prediction_ 值为所有没有采样到该样本进行训练的基学习器预测结果均值。在得到所有的oob_prediction_ 的值后,如果问题是回归问题，则用r2_score来计算oob_score_ ，如果问题是分类问题，则用accuarcy_score来计算oob得分。

2.如果问题是回归问题，则输出多个决策树预测的均值。如果问题是分类问题，则有两种策略，第一种我们一般称之为多数投票的策略，输出最高预测频率的类别；第二种是sklearn中的概率聚合策略，通过各个学习器输出的概率分布先计算样本属于某个类别的平均概率，在对平均的概率分布取argmax以输出最可能的类别。（总的来说就是，绝对平均和加权平均的区别。）

3.在每棵树的构建过程中，随机选择特征和分割点分割开空间中的样本点，直到达到树停止生长的条件（叶节点样本数量为1或者树的深度达到最大深度）。由于随机性，一棵树的分裂和生成结果不具有代表性，为了提升稳定性，孤立森林将构建t棵树（默认值为100），每棵树在生成时的数据集是是从原始数据集上抽样出来的$\psi$​​​个样本（默认值为256，不足将使用全部数据），依据前述的方法构建t棵树。依据t棵树的结果得到每个样本在每棵树中的路径长度h(x)，求取均值$Eh(x)$,依据公式$s(x,n)=2^{-\frac{Eh(x)}{c(n)}}$​，计算每个样本的孤立指标（越大，越可能是异常点）。最后根据计算出来的指标进行排序，取出前5%的异常孤立指标的样本作为异常点即可。



